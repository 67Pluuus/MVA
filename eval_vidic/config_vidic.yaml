# 路径配置
paths:
  # Benchmark 基础路径
  Benchmark_name: "ViDiC-1K"
  video_base_dir: "Benchmark/ViDiC-1K/test"
  # 数据集 JSON 路径
  json_file: "Benchmark/ViDiC-1K/test/metadata.json"

# 模型配置
models:
  main_model_path: "Qwen/Qwen3-VL-2B-Instruct"
  api_key: "7117a451621443b1b550a08acadad5e1.Mljp89b7Rwz7SeiA"

# 运行参数
parameters:
  describe_frames: 8
  num_gpus: 1
  # 任务数量, -1 表示所有
  num_tasks: -1
  save_key_frames: false
  save_video_frames: false
  number_type: "ABC"

  # Agent 参数
  agent:
    global_max_iterations: 20 # 通过Tool Agent获取信息的全局最大迭代次数
    skip_iteration: false # 是否跳过初始化后的迭代过程 (仅用于测试或者快速预览)
    frame_bank_size: 16 # 每个视频最多取这么多帧
    initial_acceleration: 1.0
    initial_score: 0.5

  type_watermark: "video_tag" # 水印类型
  # 可选模式 (可叠加, 如"video_tag+temporal_tag"):
  # "video_tag": 视频标签 (左上角)
  # "temporal_tag": 时间戳 (左上角)
  # "trans_frame": 转场帧)
  # "none": 无水印
  priority_score_k: 1.0 # 优先级计算中加速权重k的值，默认1.0
  priority_score_t: 1.0 # 优先级计算中当前分数权重t的值，默认1.0

# 提示词
prompts:
  # 最终回答提示词
  # 【中文对照】
  # /*任务描述*/
  # 你是一个多视频问答任务中的答案生成模型。你将接收来自不同视频的多个关键帧。每个帧的左上角都有一个标签，指示它属于哪个视频（例如，“Video A”，“Video B”等）, 以及在这个视频中的对应时间戳。
  #
  # 你还将获得每个视频的文本描述：
  # {DESCRIPTIONS}
  #
  # 问题："{QUESTION}"
  # 选项："{OPTIONS}"
  #
  # 你的任务是结合分析所有提供的关键帧以及视频描述，并回答问题。请注意：
  # 1. 每一帧的视觉内容
  # 2. 每个视频的文本摘要
  # 3. 每一帧属于哪个视频（由标签指示）
  # 4. 来自不同视频的帧之间的异同
  # 5. 与回答问题相关的具体细节
  #
  # **输出格式：**
  # 仅输出你的答案（例如，“A”，“B”，“C”或“D”），不要有任何额外的解释、推理或文本。
  video_description: |
    /no_think
    /* Task Description */
    You are a helpful describer in a multi-video Q&A task. You are analyzing frames from **{VIDEO_LABEL}**.
    Question: "{QUESTION}"

    You are provided with a set of frames from this video.
    Your task is to generate a **preliminary description** of the visual content in these frames.

    /* Requirements */
    - **Focus on the Question**: Describe ONLY the visual details that are relevant to answering the question.
    - **Be Factural**: Do not hallucinate. Describe what is visible.
    - **Be Concise**: Provide a dense summary of important visual cues.

    Output the description directly, without any additional text.

  answer: |
    /no_think
    /*Task Description*/
    You are an answer generation model in a multi-video Q&A task. You will receive multiple keyframes from different videos. Each frame has a label in the upper left corner indicating which video it belongs to (e.g., "Video A", "Video B", etc.), and the corresponding timestamp in this video.

    You are also provided with textual descriptions for each video:
    {DESCRIPTIONS}

    Question: "{QUESTION}"
    Options: "{OPTIONS}"

    Your task is to analyze all the provided keyframes AND the video descriptions to answer the question. Pay attention to:
    1. The visual content of each frame
    2. The textual summary of each video
    3. Which video each frame belongs to (indicated by the label)
    4. The differences and similarities between frames from different videos
    5. The specific details relevant to answering the question

    **Output Format:**
    Output only your answer (e.g., "A", "B", "C", or "D"), without any additional explanation, reasoning, or text.

  # 【中文对照】
  # /* 任务描述 */
  # 你是多视频问答任务中的工具代理。你将会收到{VIDEO_LABEL}的一组采样帧, 你需要根据这些帧完成以下两项任务：
  # 1. 评估提供的**帧库**（Frame Bank）中每一帧对回答问题的重要性。
  # 2. 根据当前的探索状态，决定下一个采样动作。
  #
  # 问题："{QUESTION}"
  # 当前感受野：{START_TIME:.2f}s 到 {END_TIME:.2f}s。

  #
  # /* 任务 1：评分 */
  # - 对帧库中的每一帧打分（0.01-1.00）。高分表示包含关键证据。
  #
  # /* 任务 2：决定动作 */
  # 基于当前的视觉信息和问题，选择一个选项（1-6）：
  # 1. **聚焦中间，替换当前帧**
  # 2. **聚焦中间，保留当前帧**
  # 3. **聚焦开头/结尾，替换当前帧**（仅当覆盖全局时）
  # 4. **聚焦开头/结尾，保留当前帧**（仅当覆盖全局时）
  # 5. **带偏移的全局均匀采样，替换当前帧**
  # 6. **终止视频探索**
  #
  # /* 输出格式 */
  # Scores: <帧库分数的空格分隔列表>
  # Decision: Option <选项数字> [Range: <开始>, <结束>] (选项5/6不需要Range)
  tool_combined_action: |
    /no_think
    /* Task Description */
    You are a Tool Agent in a multi-video Q&A task. You will receive a series of frames sampled from {VIDEO_LABEL}. You need to perform TWO tasks simultaneously:
    1. Evaluate the importance of each frame in the provided **Frame Bank** for answering the question.
    2. Decide the next sampling action based on the current exploration status.

    Question: "{QUESTION}"
    Current Receptive Field (Just explored): {START_TIME:.2f}s to {END_TIME:.2f}s.
    Is Global View: {IS_GLOBAL}
    You are provided with frames from the Frame Bank (shown as images).
    **Important: Each frame has a specific timestamp (in seconds) marked in the top-left corner. Use these timestamps to ground your reasoning.**

    /* Task 1: Scoring */
    - Assign a score (0.01-1.00) to EACH provided frame based on its relevance to the question. 
    - 1.00: The frame contains critical, direct visual evidence that answers the question.
    - 0.50: The frame provides useful context but is not decisive.
    - 0.01: The frame is irrelevant, blurry, or redundant.

    /* Task 2: Decide Action */
    Choose one option (1-6) based on current visual info. 
    **Crucial: For Options 1-4, you MUST specify the target time range [start, end] you want to explore.**

    1. **Focus Middle, Replace current frames**: Explore the middle part of the video; DISCARD current frames.
    2. **Focus Middle, Keep current frames**: Explore the middle part of the video; RETAIN current frames.
    3. **Focus Start/End, Replace current frames**: Explore the start/end part of the video; DISCARD current frames. (Valid ONLY when current view covers the whole video)
    4. **Focus Start/End, Keep current frames**: Explore the start/end part of the video; RETAIN current frames. (Valid ONLY when current view covers the whole video)
    5. **Global Uniform Sampling with offset, Replace current frames**: Re-sample global; DISCARD current.
    6. **Terminate video exploration**: Stop if sufficient info found.

    /* Output Format */
    Scores: <space-separated list of scores for the frame bank>
    Decision: Option <number> [Range: <start>, <end>] (Range optional for Option 5/6)

  # 【中文对照】
  # /* 任务描述 */
  # 你是多视频问答任务中的描述代理。你需要同时完成两项任务：
  # 1. 为新提供的帧生成简明扼要的描述（**新观察**）。
  # 2. 评估**完整描述**（先前描述 + 新观察）的质量并决定是否终止。
  #
  # 问题："{QUESTION}"
  # 先前的描述："{DESC_OLD}"
  # 其他视频的描述：
  # {OTHER_DESCS_TEXT}
  #
  # /* 任务 1：描述 */
  # - 仅描述新帧中与问题相关的视觉细节。不要重复已知信息。
  #
  # /* 任务 2：评估与终止 */
  # - 评分（0.01-1.00）：完整描述对回答问题的帮助程度。
  # - 终止检查 1（当前视频）：是否已挖掘完该视频的所有信息？
  # - 终止检查 2（全局任务）：结合所有视频，是否有足够证据得出结论？
  #
  # /* 输出格式 */
  # New Description: <新帧的描述>
  # ---
  # Score: <分数>
  # Video Terminated: <True/False>
  # Global Terminated: <True/False>
  desc_combined_action: |
    /no_think
    /* Task Description */
    You are a Description Agent in a multi-video Q&A task. You will receive a series of frames sampled from {VIDEO_LABEL}. You need to perform TWO tasks simultaneously:
    1. Generate a concise description for the NEW provided frames (**New Observation**).
    2. Evaluate the quality of the **FULL Description** (Previous + New) and decide termination.

    Question: "{QUESTION}"
    Previous Description: "{DESC_OLD}"
    Other Videos: 
    {OTHER_DESCS_TEXT}

    /* Task 1: Description */
    - Describe ONLY the visual details in the frames relevant to the question. Do not repeat known info.

    /* Task 2: Evaluation & Termination */
    - Score (0.01-1.00): How helpful is the FULL description for answering the question?
    - Termination Check 1 (Current Video): Have we fully mined THIS video? (True/False)
    - Termination Check 2 (Global Task): Do we have enough evidence from ALL videos to answer conclusively? (True/False)

    /* Output Format */
    New Description: <description of new frames>
    ---
    Score: <score>
    Video Terminated: <True/False>
    Global Terminated: <True/False>
